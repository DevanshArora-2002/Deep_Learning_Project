{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87880f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c624827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "trans=transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=0.1),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3045daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data=os.listdir(\"TRAIN\")\n",
    "all_paths=[]\n",
    "all_labels=[]\n",
    "for i,path in enumerate(train_data):\n",
    "    full_path=\"TRAIN/\"+path+\"/\"\n",
    "    lst=os.listdir(full_path)\n",
    "    lst=[full_path+i for i in lst]\n",
    "    all_paths.extend(lst)\n",
    "    all_labels.extend([i for j in range(len(lst))])\n",
    "all_paths=np.array(all_paths)\n",
    "all_labels=np.array(all_labels)\n",
    "train_lst,val_lst,train_labels,val_labels=train_test_split(all_paths,all_labels,test_size=0.3)\n",
    "val_lst,test_lst,val_labels,test_labels=train_test_split(val_lst,val_labels,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec31cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self,paths,labels,transform=None):\n",
    "        self.transform=transform\n",
    "        self.images_path=paths\n",
    "        self.labels=labels\n",
    "        if(transform is not None):\n",
    "            self.images_path=np.append(self.images_path,self.images_path)\n",
    "            self.labels=np.append(self.labels,self.labels)\n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "    def __getitem__(self,idx):\n",
    "        hf=len(self.images_path)/2\n",
    "        img=self.images_path[idx]\n",
    "        image=cv2.imread(img)\n",
    "        image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        resized_image = cv2.resize(image,(299,299), interpolation=cv2.INTER_CUBIC)\n",
    "        resized_image=np.array(resized_image)\n",
    "        resized_image=torch.tensor(resized_image)\n",
    "        if(self.transform is not None):\n",
    "            half=len(self.images_path)/2\n",
    "            if(idx>=half):\n",
    "                resized_image=torch.reshape(resized_image,(3,299,299))\n",
    "                resized_image=resized_image.to(torch.float32)\n",
    "                resized_image=self.transform(resized_image)\n",
    "                return resized_image,self.labels[idx]\n",
    "        resized_image=torch.reshape(resized_image,(3,299,299))\n",
    "        resized_image=resized_image.to(torch.float32)\n",
    "        return resized_image,self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f486e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=DataSet(train_lst,train_labels,trans)\n",
    "val_dataset=DataSet(val_lst,val_labels,trans)\n",
    "test_dataset=DataSet(test_lst,test_labels,trans)\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=16,shuffle=True)\n",
    "val_dataloader=DataLoader(val_dataset,batch_size=16,shuffle=True)\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410108be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,f1_score\n",
    "def get_acc(pred,out):\n",
    "    arr=pred.to('cpu').detach()\n",
    "    arr=np.array(arr)\n",
    "    arr2=out.to('cpu').detach()\n",
    "    arr2=np.array(arr2)\n",
    "    return accuracy_score(arr,arr2)\n",
    "def get_prec(pred,out):\n",
    "    arr=pred.to('cpu').detach()\n",
    "    arr=np.array(arr)\n",
    "    arr2=out.to('cpu').detach()\n",
    "    arr2=np.array(arr2)\n",
    "    return precision_score(arr,arr2,average='macro')\n",
    "def get_f1(pred,out):\n",
    "    arr=pred.to('cpu').detach()\n",
    "    arr=np.array(arr)\n",
    "    arr2=out.to('cpu').detach()\n",
    "    arr2=np.array(arr2)\n",
    "    return f1_score(arr,arr2,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        test_acc=0\n",
    "        test_prec=0\n",
    "        test_f1=0\n",
    "        for i,(inputs, targets) in enumerate(test_dataloader):\n",
    "            outputs = model(inputs)\n",
    "            targets=targets.to(torch.long)\n",
    "            targets=targets.to('cpu')\n",
    "            outputs=outputs.to('cpu')\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            outputs=torch.argmax(outputs,dim=1)\n",
    "            test_acc+=get_acc(outputs,targets)\n",
    "            test_prec+=get_prec(outputs,targets)\n",
    "            test_f1+=get_f1(outputs,targets)\n",
    "        test_acc/=(i+1)\n",
    "        total_loss/=(i+1)\n",
    "        test_prec/=(i+1)\n",
    "        test_f1/=(i+1)\n",
    "        sen = f\"Testing ,Running Loss {total_loss} ,Accuracy:{test_acc},Precision:{test_prec},F1:{test_f1}\"\n",
    "        print(sen)\n",
    "        return total_loss,test_acc,test_prec,test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_model(list_models,filename):\n",
    "    pickle.dump(list_models, open(filename, 'wb'))\n",
    "def load_model(filename):\n",
    "    list_models=pickle.load(open(filename, 'rb'))\n",
    "    return list_models\n",
    "filename=\"Weights/Inception\"\n",
    "model=load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36290d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss,test_acc,test_prec,test_f1=test(model,test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
